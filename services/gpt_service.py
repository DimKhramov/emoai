from openai import AsyncOpenAI
import os
from dotenv import load_dotenv
from pathlib import Path

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI
_openai_client = None

def get_openai_client():
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI"""
    global _openai_client
    if _openai_client is None:
        _openai_client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            timeout=30.0
        )
    return _openai_client

def load_system_prompt() -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞"""
    prompt_path = Path(__file__).parent.parent / "prompts" / "system_prompt.txt"
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except FileNotFoundError:
        return "–¢—ã ‚Äî ¬´–≠–º–æ-–¥—Ä—É–≥¬ª, –ò–ò-–∞–≥–µ–Ω—Ç –≤ –¢–µ–ª–µ–≥—Ä–∞–º–µ. –ë—É–¥—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º."

async def chat_with_gpt(prompt: str, model: str = "gpt-4o-mini", conversation_history: list = None) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ ChatGPT –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç.

    :param prompt: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è ChatGPT.
    :param model: –ú–æ–¥–µ–ª—å ChatGPT (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "gpt-4o-mini").
    :param conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    :return: –û—Ç–≤–µ—Ç –æ—Ç ChatGPT.
    """
    client = get_openai_client()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    system_prompt = load_system_prompt()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    messages = [{"role": "system", "content": system_prompt}]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
    if conversation_history:
        messages.extend(conversation_history[-10:])  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
    messages.append({"role": "user", "content": prompt})

    try:
        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.8,  # –î–µ–ª–∞–µ–º –æ—Ç–≤–µ—Ç—ã –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º–∏
            max_tokens=500    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ GPT API: {e}")
        return "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Å–µ–π—á–∞—Å –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ç–≤–µ—Ç–æ–º. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑! üòÖ"

async def close_openai_client():
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π OpenAI –∫–ª–∏–µ–Ω—Ç"""
    global _openai_client
    if _openai_client:
        try:
            await _openai_client.close()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}")
        finally:
            _openai_client = None